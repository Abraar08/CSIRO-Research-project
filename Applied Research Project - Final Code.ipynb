{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying keywords to measure artificial intelligence research and developments in Australia between 2011-2022â€‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name(s) & ID(s) of Group Members: \n",
    "- s3846691@student.rmit.edu.au Abraar\n",
    "- s3839204@student.rmit.edu.au Adrian\n",
    "- s3870059@student.rmit.edu.au Larry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"con\"></a>\n",
    "1. [Introduction](#in) \n",
    "2. [Lemmatization](#lem) \n",
    "3. [Tokenization](#tok)\n",
    "4. [Word2Vec](#w2v)\n",
    "5. [Bert](#bert)\n",
    "6. [TF-IDF](#tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a name=\"intro\"></a>\n",
    "\n",
    "## 1.1 Dataset Source <a name=\"DatasetSource\"></a>\n",
    "The dataset was found from [Lens.org](https://lens.org).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset Details <a name=\"DatasetDetails\"></a>\n",
    "\n",
    "The dataset contains 10k observations and 32 column variables. This data includes all research paper under the jurisdiction of Australia in the past 10 years. Dataset includes information such as Lens ID, publication data, application number, title, abstract, applicants, inventors, CPC classifications, number citations etc. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code imports all the required packages for this project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess import document_preprocess\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import pickle\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code changes the setting to disregard warning messages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code imports and reads data from csv file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Lens Data 2011-2022.csv\")\n",
    "train = list((data['Abstract']+data['Title']).values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Display Key</th>\n",
       "      <th>Lens ID</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Application Number</th>\n",
       "      <th>Application Date</th>\n",
       "      <th>Priority Numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>Extended Family Size</th>\n",
       "      <th>Sequence Count</th>\n",
       "      <th>CPC Classifications</th>\n",
       "      <th>IPCR Classifications</th>\n",
       "      <th>US Classifications</th>\n",
       "      <th>NPL Citation Count</th>\n",
       "      <th>NPL Resolved Citation Count</th>\n",
       "      <th>NPL Resolved Lens ID(s)</th>\n",
       "      <th>NPL Resolved External ID(s)</th>\n",
       "      <th>NPL Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2020/289790 B2</td>\n",
       "      <td>008-698-137-173-075</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2020/289790 A</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>AU 2020/289790 A;;AU 2017/345067 A;;US 2016152...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>G05D1/042;;G05D1/102;;G05D1/1062;;G05D1/0088;;...</td>\n",
       "      <td>G05D1/06;;G01C21/00;;G06T7/73;;G08G5/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2016/253569 B2</td>\n",
       "      <td>004-265-997-185-317</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2016/253569 A</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>AU 2015/904490 A</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>E04H17/12;;E04H17/10;;E04H17/20;;E04H17/24</td>\n",
       "      <td>E04H17/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2018/306411 B2</td>\n",
       "      <td>035-019-491-150-417</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2018/306411 A</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>KR 20180088375 A;;US 201762538034 P;;KR 201800...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>A61K9/51;;A61K31/713;;A61P35/00;;C12N15/113;;C...</td>\n",
       "      <td>A61K31/713;;A61K9/51;;A61P35/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2017/205693 B2</td>\n",
       "      <td>026-585-572-258-403</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2017/205693 A</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>EP 16179291 A;;EP 16150631 A;;EP 16191462 A;;E...</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>A61K47/60;;A61P19/00;;A61K47/60;;A61K38/22</td>\n",
       "      <td>A61K47/60;;A61P19/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2017/225767 B2</td>\n",
       "      <td>049-789-773-402-263</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2017/225767 A</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>US 201662302430 P;;US 2017/0020448 W</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>G01N35/02;;G01N35/00732;;G01N2035/0441;;G01N35...</td>\n",
       "      <td>G01N21/13;;G01N21/31;;G01N21/63;;G01N33/02;;G0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2020/239823 B2</td>\n",
       "      <td>061-282-055-514-561</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2020/239823 A</td>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>AU 2020/239823 A;;AU 2016/247473 A;;US 2015621...</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>A01N37/22;;A01N37/22;;A01N25/08;;A01N25/34;;A0...</td>\n",
       "      <td>A01N37/22;;A01N43/36;;A01N51/00;;A01N53/00;;A0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2017/392966 B2</td>\n",
       "      <td>068-513-652-517-891</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2017/392966 A</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>IN 201731001199 A;;IB 2017058408 W</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>A01N47/40;;A01N47/40;;A01N53/00;;A01N25/12;;A0...</td>\n",
       "      <td>A01N47/40;;A01N53/00;;A01P7/04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2020/294444 B2</td>\n",
       "      <td>067-623-277-289-76X</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2020/294444 A</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>US 201916445981 A;;US 2020/0029705 W</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>H04L67/104;;H04W88/04;;H04W48/20;;H04L67/16;;H...</td>\n",
       "      <td>H04L65/80;;H04L67/104;;H04W8/00;;H04W40/24;;H0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2021/204749 B2</td>\n",
       "      <td>087-242-273-655-845</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2021/204749 A</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>AU 2021/204749 A;;AU 2019/256245 A;;CN 2018083...</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>A61K38/26;;A61K47/68;;A61P3/10;;C07K1/107;;C07...</td>\n",
       "      <td>C07K14/605;;A61K38/26;;A61K47/68;;A61P3/10;;C0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>AU</td>\n",
       "      <td>B2</td>\n",
       "      <td>AU 2018/426934 B2</td>\n",
       "      <td>108-511-371-966-818</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>AU 2018/426934 A</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>EP 2018064759 W</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>A61F13/496;;A61F13/51394;;A61F13/51496;;A61F13...</td>\n",
       "      <td>A61F13/496;;A61F13/513;;A61F13/514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Jurisdiction Kind        Display Key              Lens ID  \\\n",
       "0   1           AU   B2  AU 2020/289790 B2  008-698-137-173-075   \n",
       "1   2           AU   B2  AU 2016/253569 B2  004-265-997-185-317   \n",
       "2   3           AU   B2  AU 2018/306411 B2  035-019-491-150-417   \n",
       "3   4           AU   B2  AU 2017/205693 B2  026-585-572-258-403   \n",
       "4   5           AU   B2  AU 2017/225767 B2  049-789-773-402-263   \n",
       "5   6           AU   B2  AU 2020/239823 B2  061-282-055-514-561   \n",
       "6   7           AU   B2  AU 2017/392966 B2  068-513-652-517-891   \n",
       "7   8           AU   B2  AU 2020/294444 B2  067-623-277-289-76X   \n",
       "8   9           AU   B2  AU 2021/204749 B2  087-242-273-655-845   \n",
       "9  10           AU   B2  AU 2018/426934 B2  108-511-371-966-818   \n",
       "\n",
       "  Publication Date  Publication Year Application Number Application Date  \\\n",
       "0       2022-03-31              2022   AU 2020/289790 A       2020-12-16   \n",
       "1       2022-03-31              2022   AU 2016/253569 A       2016-11-02   \n",
       "2       2022-03-31              2022   AU 2018/306411 A       2018-07-30   \n",
       "3       2022-03-31              2022   AU 2017/205693 A       2017-01-05   \n",
       "4       2022-03-31              2022   AU 2017/225767 A       2017-03-02   \n",
       "5       2022-03-31              2022   AU 2020/239823 A       2020-09-26   \n",
       "6       2022-03-31              2022   AU 2017/392966 A       2017-12-27   \n",
       "7       2022-03-31              2022   AU 2020/294444 A       2020-04-24   \n",
       "8       2022-03-31              2022   AU 2021/204749 A       2021-07-07   \n",
       "9       2022-03-31              2022   AU 2018/426934 A       2018-06-05   \n",
       "\n",
       "                                    Priority Numbers  ...  \\\n",
       "0  AU 2020/289790 A;;AU 2017/345067 A;;US 2016152...  ...   \n",
       "1                                   AU 2015/904490 A  ...   \n",
       "2  KR 20180088375 A;;US 201762538034 P;;KR 201800...  ...   \n",
       "3  EP 16179291 A;;EP 16150631 A;;EP 16191462 A;;E...  ...   \n",
       "4               US 201662302430 P;;US 2017/0020448 W  ...   \n",
       "5  AU 2020/239823 A;;AU 2016/247473 A;;US 2015621...  ...   \n",
       "6                 IN 201731001199 A;;IB 2017058408 W  ...   \n",
       "7               US 201916445981 A;;US 2020/0029705 W  ...   \n",
       "8  AU 2021/204749 A;;AU 2019/256245 A;;CN 2018083...  ...   \n",
       "9                                    EP 2018064759 W  ...   \n",
       "\n",
       "  Extended Family Size Sequence Count  \\\n",
       "0                   13              0   \n",
       "1                    5              0   \n",
       "2                   13              0   \n",
       "3                    8              0   \n",
       "4                    6              0   \n",
       "5                   12              0   \n",
       "6                   15              0   \n",
       "7                   10              0   \n",
       "8                   15              0   \n",
       "9                   12              0   \n",
       "\n",
       "                                 CPC Classifications  \\\n",
       "0  G05D1/042;;G05D1/102;;G05D1/1062;;G05D1/0088;;...   \n",
       "1         E04H17/12;;E04H17/10;;E04H17/20;;E04H17/24   \n",
       "2  A61K9/51;;A61K31/713;;A61P35/00;;C12N15/113;;C...   \n",
       "3         A61K47/60;;A61P19/00;;A61K47/60;;A61K38/22   \n",
       "4  G01N35/02;;G01N35/00732;;G01N2035/0441;;G01N35...   \n",
       "5  A01N37/22;;A01N37/22;;A01N25/08;;A01N25/34;;A0...   \n",
       "6  A01N47/40;;A01N47/40;;A01N53/00;;A01N25/12;;A0...   \n",
       "7  H04L67/104;;H04W88/04;;H04W48/20;;H04L67/16;;H...   \n",
       "8  A61K38/26;;A61K47/68;;A61P3/10;;C07K1/107;;C07...   \n",
       "9  A61F13/496;;A61F13/51394;;A61F13/51496;;A61F13...   \n",
       "\n",
       "                                IPCR Classifications US Classifications  \\\n",
       "0            G05D1/06;;G01C21/00;;G06T7/73;;G08G5/02                NaN   \n",
       "1                                          E04H17/20                NaN   \n",
       "2                    A61K31/713;;A61K9/51;;A61P35/00                NaN   \n",
       "3                               A61K47/60;;A61P19/00                NaN   \n",
       "4  G01N21/13;;G01N21/31;;G01N21/63;;G01N33/02;;G0...                NaN   \n",
       "5  A01N37/22;;A01N43/36;;A01N51/00;;A01N53/00;;A0...                NaN   \n",
       "6                     A01N47/40;;A01N53/00;;A01P7/04                NaN   \n",
       "7  H04L65/80;;H04L67/104;;H04W8/00;;H04W40/24;;H0...                NaN   \n",
       "8  C07K14/605;;A61K38/26;;A61K47/68;;A61P3/10;;C0...                NaN   \n",
       "9                 A61F13/496;;A61F13/513;;A61F13/514                NaN   \n",
       "\n",
       "  NPL Citation Count NPL Resolved Citation Count NPL Resolved Lens ID(s)  \\\n",
       "0                  0                           0                     NaN   \n",
       "1                  0                           0                     NaN   \n",
       "2                  0                           0                     NaN   \n",
       "3                  0                           0                     NaN   \n",
       "4                  0                           0                     NaN   \n",
       "5                  0                           0                     NaN   \n",
       "6                  0                           0                     NaN   \n",
       "7                  0                           0                     NaN   \n",
       "8                  0                           0                     NaN   \n",
       "9                  0                           0                     NaN   \n",
       "\n",
       "  NPL Resolved External ID(s)  NPL Citations  \n",
       "0                         NaN            NaN  \n",
       "1                         NaN            NaN  \n",
       "2                         NaN            NaN  \n",
       "3                         NaN            NaN  \n",
       "4                         NaN            NaN  \n",
       "5                         NaN            NaN  \n",
       "6                         NaN            NaN  \n",
       "7                         NaN            NaN  \n",
       "8                         NaN            NaN  \n",
       "9                         NaN            NaN  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class document_preprocess:\n",
    "    \n",
    "    def __init__(self,lemmatize=True, stop_words=True, singleton=True, valid_word=True, custom_stop_words=[]):\n",
    "        self.lemmatize=lemmatize\n",
    "        self.stop_words=stop_words\n",
    "        self.singleton=singleton\n",
    "        self.valid_word=valid_word\n",
    "        self.custom_stop_words=custom_stop_words\n",
    "        self.nlp = spacy.load(\"en_core_sci_lg\")\n",
    "\n",
    "    def filter_word(self, text):\n",
    "        \n",
    "        filtered_sentence=[]\n",
    "        doc = self.nlp(str(text).lower())\n",
    "        \n",
    "        for word in doc:\n",
    "            filters=[]\n",
    "            if self.lemmatize:\n",
    "                word=word.vocab[word.lemma_]\n",
    "\n",
    "            filters.append(True if word.is_alpha else False)\n",
    "\n",
    "            # dont append word if it is a stop word\n",
    "            if self.stop_words:\n",
    "                filters.append(False if word.is_stop else True)\n",
    "\n",
    "            # dont append word if its length is 1\n",
    "            if self.singleton:\n",
    "                filters.append(False if len(word.text)==1 else True)\n",
    "\n",
    "            # dont append word if it belongs to custom stop word\n",
    "            if len(self.custom_stop_words)>0:\n",
    "                filters.append(False if word.text in self.custom_stop_words else True)\n",
    "\n",
    "            # If there is a valid word vector\n",
    "            if self.valid_word:\n",
    "                filters.append(False if word.vector.sum()==0 else True)\n",
    "\n",
    "            if all(filters):\n",
    "                filtered_sentence.append(word.text)\n",
    "\n",
    "        return filtered_sentence\n",
    "    \n",
    "    def make_ngrams(self,s,n):\n",
    "        ''' \n",
    "        Input: String\n",
    "        Description: Create N-grams of a string\n",
    "        Output: n-grams\n",
    "        '''\n",
    "        ngrams=[]\n",
    "        s=self.nlp(s)\n",
    "        for n in range(1,n+1):\n",
    "            ngrams.extend([s[i:i+n] for i in range(len(s)-n+1)])\n",
    "        return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code lemmatize data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = document_preprocess(lemmatize=True, stop_words=True, singleton=True, custom_stop_words=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This chunk of code tokenize data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10000 of 10000) |##################| Elapsed Time: 0:07:45 Time:  0:07:45\n"
     ]
    }
   ],
   "source": [
    "tokens=[]\n",
    "\n",
    "for text in pbar(train):\n",
    "    filtered_list = ob.filter_word(text)\n",
    "    filtered_string =' '.join([str(item) for item in filtered_list])\n",
    "    tokens.append(ob.make_ngrams(filtered_string,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_doc=[]\n",
    "for i in tokens:\n",
    "    test_tok=''\n",
    "    for tok in i:\n",
    "        if len(tok)==2:\n",
    "            test_tok=test_tok + ' ' + str(tok[0])+'_'+str(tok[1])\n",
    "    preprocessed_doc.append(test_tok[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token=[]\n",
    "for i in tokens:\n",
    "    for tok in i:\n",
    "        final_token.append(str(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokens.pkl', 'wb') as f:\n",
    "    pickle.dump(final_token, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_doc.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessed_doc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Parameters for adding preprocessing operations to the pipeline \n",
    "#### Description: Class containing functions for preprocessing and n-grams\n",
    "#### Input: Text document | Output: Preprocessed text\n",
    "#### Description: This function inputs a particular document text, creates it to an nlp object and then performs the following preprocessing operations:\n",
    "1. Lemmatization\n",
    "2. Stop words removal\n",
    "3. Singleton removal\n",
    "4. Custom stop words removal\n",
    "5. Valid word check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word2Vec <a name=\"w2v\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_doc.pkl', 'rb') as f:\n",
    "    preprocessed_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokenized=[word.lower().split() for word in preprocessed_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_token=[]\n",
    "for i in doc_tokenized:\n",
    "    for j in i:\n",
    "        fin_token.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokens=[]\n",
    "\n",
    "for i in fin_token:\n",
    "    spacy_tokens.append(i.replace('_',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the cosine similarity scores\n",
    "def cos_sim(vector1, vector2):\n",
    "    cosine_similarity = 1 - distance.cosine(vector1, vector2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Artificial Intelligence` as target keyword set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_={}\n",
    "error_=[]\n",
    "unique_tokens=list(set(spacy_tokens))\n",
    "\n",
    "\n",
    "for i in unique_tokens:\n",
    "    try:\n",
    "        dict_[i] = cos_sim(nlp(i).vector, nlp(\"artificial intelligence\").vector)\n",
    "    except:\n",
    "        error_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = dict(sorted(dict_.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(dict_, index=[0]).T\n",
    "results.to_csv(\"AI_cosine_similarity_results_w2v.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BERT <a name=\"bert\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82a6e21f3db4ff4930643a8667dc58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e645a748fe7f4b30999355b6ac382025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acdfa7a6b004d5db0552f12d24a37e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d925e942544137a99f499ff5a517c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aed07674a54f0180a868d3523a6772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e173806de7994dc4a5f8162a1f0a20e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92211f4a6f1f492faf4427268ed264c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c14d8f5f31a48bbb7048fe8d53f5a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe57b3b258145ca9dcc0aea9e6782ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f184f30cc348b3b069a398f71e2a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfec6c8ed33e493687c66e7f113f93b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154e1f0c17274d26946ce9535eb4538d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2161d4dce58c46d09b8b38972633523f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing underscore\n",
    "bert_tokens=[]\n",
    "\n",
    "for i in fin_token:\n",
    "    bert_tokens.append(i.replace('_',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the cosine similarity scores\n",
    "def cos_sim(vector1, vector2):\n",
    "    cosine_similarity = 1 - distance.cosine(vector1, vector2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to keyword `artificial intelligence`\n",
    "dict_={}\n",
    "error_=[]\n",
    "unique_tokens=list(set(bert_tokens))\n",
    "\n",
    "\n",
    "for i in unique_tokens:\n",
    "    try:\n",
    "        dict_[i] = cos_sim(sbert_model.encode(i), sbert_model.encode('artificial intelligence'))\n",
    "    except:\n",
    "        error_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank cosine similarity by Descending order\n",
    "dict_ = dict(sorted(dict_.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Results\n",
    "results=pd.DataFrame(dict_, index=[0]).T\n",
    "results.to_csv(\"AI_cosine_similarity_results_bert.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TF-IDF <a name=\"tf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first 5000 documents\n",
    "data = pd.read_csv(r\"data\\Lens-AU.csv\")\n",
    "train = list((data['Abstract']+data['Title']).values.astype('U'))\n",
    "train=train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pre-process document\n",
    "ob=document_preprocess(lemmatize=True, stop_words=True, singleton=True, custom_stop_words=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_doc=[]\n",
    "\n",
    "for text in pbar(train):\n",
    "    filtered_list=ob.filter_word(text)\n",
    "    filtered_string =' '.join([str(item) for item in filtered_list])\n",
    "    preprocessed_doc.append(filtered_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize, using bi-grams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(preprocessed_doc).todense()\n",
    "\n",
    "df=pd.DataFrame(X, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector1, vector2):\n",
    "    cosine_similarity = 1 - distance.cosine(vector1, vector2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_={}\n",
    "\n",
    "for i in df.columns:\n",
    "    dict_[i] = cos_sim(df[i], df[\"artificial intelligence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Results\n",
    "dict_ = dict(sorted(dict_.items(), key=lambda item: item[1], reverse=True))\n",
    "results=pd.DataFrame(dict_, index=[0]).T\n",
    "results.to_csv(\"AI_cosine_similarity_results_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
